[![](https://img.shields.io/badge/Plugin-Flink-brightgreen)](https://flink.apache.org/) [![](https://img.shields.io/badge/Plugin-Kafka-brightgreen)](http://kafka.apache.org/)
# 基于Flink的用户行为分析(流式数据处理模块)
业务对实时性要求较高，因此选用Flink作为流式数据处理的框架。项目中综合运用Flink的各种API，基于EventTime去处理基本的业务需求，并灵活地使用底层的processFunction，基于状态编程和CEP去处理更加复杂的情形。
功能模块的情况：
- 实时统计分析
  - 基于点击行为的实时热门商品统计(Done)
  - 实时访问流量统计(Done)
  - 基于浏览行为(Todo)
  - 实时热门页面流量统计(Todo)
  - APP市场推广渠道统计(Done)
  - PV和UV统计(Todo)
- 偏好统计
  - 收藏、喜欢、评分、打标签(Todo)
  - 用户画像，推荐(Todo)
- 业务流程及风险控制
  - 恶意登录监控(Done)
  - 订单支付失效监控(Done)
  - 刷单监控(Todo)
  - 页面广告点击黑名单过滤(Done)
  - 实时对账(Done)

## 已完成模块(Done)
### 实时统计—热门商品统计
基于用户行为日志:分析最近5分钟热门商品 30s更新一次
- 基本需求
  - 统计近1小时内的热门商品，每5分钟更新一次
  - 热门度用浏览器次数（“pv”）来衡量
- 解决思路
  - 在所有用户行为数据中，过滤出浏览（“pv”）行为进行统计
  - 构建滑动窗口，窗口长度为1小时，滑动距离为5分钟
  - 用 event time
  
### 实时统计—流量统计
基于服务器日志:分析最近一分钟访问最频繁的url topN 5秒更新一次
- 基本需求
  - 从web服务器的日志中，统计实时的热门访问页面
  - 统计每分钟的ip访问量，取出访问量最大的5个地址，没5秒更新一次
- 解决思路
  - 将apache服务器日志中的时间，转换为时间戳，作为Event Time
  - 构建滑动窗口，窗口长度为1分钟，滑动距离为5秒 
  
### 恶意登录监控
基于用户登录日志:实现登录风控,预警.
- 基本需求
  - 用户在短时间内频繁登录失败，有程序恶意攻击的可能
  - 同一用户（可以是不同IP）在2秒内连续两次登录失败，需要报警
- 解决思路
  - 将用户的登录失败行为存入ListState,设定定时器2秒后出发，查看ListState中有几次失败登录
  - 使用FLINK CEP 进行登录失败检测,实现更加精确的检测，可以使用CEP库实现事件流的模式匹配
  
### 订单支付实时监控
- 基本需求
  - 用户下单之后，应设置订单失效时间，以提高用户支付的意愿，并降低系统风险
  - 用户下单后15分钟未支付，则输出监控信息
- 解决思路
  - 订单超时失效CEP实现，利用CEP库进行事件流的模式匹配，并设定匹配的时间间隔
  - 订单超时失效状态处理，也可以利用状态编程，用process function实现处理逻辑

### 市场营销分析—APP市场推广统计
- 基本需求
  - 从埋点日志中，统计APP市场推广的数据指标
  - 按照不同的推广渠道，分别统计数据
- 解决思路
  - 通过过滤日志中的用户行为，按照不同的渠道进行统计
  - 可以用process function处理，得到自定义的输出数据信息
  
### 市场营销分析—页面广告统计
- 基本需求
  - 从埋点日志中，统计每小时页面广告的点击量，5秒刷新一次，并按照不同省份进行划分
  - 对于“刷单”式的频繁点击行为进行过滤，并将该用户加入黑名单
- 解决思路
  - 根据省份进行分组，创建长度为1小时、滑动距离为5秒的时间窗口进行统计
  - 可以用process function进行黑名单过滤，检测用户对同一广告的点击量，如果超过上限则将用户信息以侧输出流输出到黑名单中

### 订单支付实时对账
- 基本需求
  - 用户下单并支付后，应查询到账信息，进行实时对账
  - 如果有不匹配的支付信息或者到账信息，输出提示信息
- 解决思路
  - 使用join进行实时对账，从两条流中分别读取订单支付信息和到账信息，合并处理
  - 使用connect实时对账，用connect连接合并两条流，用coProcessFunction做匹配处理


## 待后续补充模块(Todo)
### 实时统计—PV和UV
- 基本需求
  - 从埋点日志中，统计实时的PV和UV
  - 统计每小时的访问量（PV），并且对用户进行去重（UV）
- 解决思路
  - 统计埋点日志中的PV行为，利用Set数据结构进行去重
  - 对于超大规模的数据，可以考虑用布隆过滤器进行去重


  



